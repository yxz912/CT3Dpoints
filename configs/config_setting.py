from torchvision import transforms
from utils import *

from datetime import datetime

class setting_config:
    network='Pointnet2d'
    data_path='/media/yxz/Elements/'
    label_path='/media/yxz/Elements/三维坐标表格.xlsx'
    pretrained_path = './pre_trained/'
    num_classes = 3
    input_size_h = 512
    input_size_w = 512
    input_channels = 64  ##期望最大输入
    distributed = False
    local_rank = -1
    num_workers = 4
    seed = 42
    world_size = None
    rank = None
    amp = False
    gpu_id = '0'
    batch_size = 8
    epochs = 100
    deep_supervision = False
    train_mean=[38.232197, 36.51572, 35.653538, 34.841698, 34.53333, 34.580738, 34.047516, 34.060036, 34.206978, 33.53233, 32.705063, 32.041634, 31.622137, 31.153217, 31.150137, 31.728458, 33.087917, 34.500835, 36.742702, 38.6519, 40.604202, 42.178257, 43.246384, 44.190544, 45.63717, 46.368614, 47.56692, 48.40652, 49.483063, 50.48511, 52.11055, 53.586033, 54.524574, 55.267387, 55.781773, 56.209946, 56.75095, 56.548294, 55.87988, 55.987457, 56.049385, 55.278168, 55.257957, 54.347443, 52.88909, 51.57861, 50.415432, 48.269886, 46.376873]
    train_std=[52.448204, 51.10866, 50.99893, 50.458603, 50.253628, 50.410458, 49.5592, 49.790417, 49.56057, 48.536423, 46.968967, 45.957573, 45.317444, 44.178703, 43.669712, 43.80612, 44.75504, 45.618256, 47.70623, 48.754204, 50.724133, 51.880234, 52.706825, 53.527897, 54.63882, 54.961304, 55.696304, 56.01947, 56.365795, 56.591743, 57.311337, 57.944008, 58.28007, 58.57969, 58.557964, 58.605045, 58.87404, 59.03475, 58.732353, 59.13055, 59.5588, 59.6814, 60.429745, 60.663795, 60.559544, 60.695335, 61.105843, 60.639233, 60.579075]
    val_mean=[39.282055, 37.558815, 36.63298, 35.511284, 35.066727, 34.77867, 34.578907, 34.626266, 34.479588, 33.782177, 32.853188, 31.723333, 31.229958, 30.463028, 29.488924, 29.948984, 31.383898, 33.13944, 35.63262, 37.890858, 39.179466, 42.15199, 43.81359, 45.536274, 46.321938, 46.37175, 47.204414, 48.44351, 50.438526, 51.49414, 52.46885, 53.33485, 54.411926, 55.87407, 57.803326, 57.75311, 57.93884, 57.472725, 57.8146, 57.029186, 57.242596, 57.455845, 56.718517, 55.889084, 55.489944, 53.15779, 52.072853, 50.239693, 47.704407]
    val_std=[52.40314, 51.810974, 51.09661, 50.00466, 49.89212, 49.92913, 49.784485, 49.595673, 49.323437, 48.584366, 47.070076, 45.46188, 44.520992, 43.153122, 40.85117, 41.2668, 42.437458, 43.865276, 45.96552, 48.03161, 48.73375, 51.075314, 52.468834, 54.07488, 54.704285, 54.414112, 54.89527, 55.66804, 56.711452, 57.06557, 57.241577, 57.509354, 57.75074, 58.451996, 59.323315, 59.10447, 59.277054, 58.904915, 59.20544, 58.98054, 59.5147, 60.267155, 60.56009, 60.964615, 61.792522, 61.30433, 61.756905, 61.894527, 61.44778]
    work_dir = 'results/' + network + '_' + datetime.now().strftime('%A_%d_%B_%Y_%Hh_%Mm_%Ss') + '/'

    train_transformer = transforms.Compose([
        # myToTensor(),
        # myRandomHorizontalFlip(p=0.5),
        # myRandomVerticalFlip(p=0.5),
        # myRandomRotation(p=0.5, degree=[0, 360]),
        # myResize(input_size_h, input_size_w)
    ])
    test_transformer = transforms.Compose([
        # myToTensor(),
        # myResize(input_size_h, input_size_w)
    ])

